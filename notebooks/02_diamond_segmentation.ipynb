{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diamond Segmentation Pipeline\n",
    "\n",
    "This notebook demonstrates the complete diamond segmentation pipeline using GrabCut algorithm with CLAHE preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from src.data.loader import DiamondDataLoader, DiamondShapeMapper\n",
    "from src.utils.segmentation import (\n",
    "    init_grabcut_mask,\n",
    "    preprocess_for_segmentation,\n",
    "    remove_background,\n",
    "    visualize_mask\n",
    ")\n",
    "from src.utils.visualization import (\n",
    "    annotate_segmentation,\n",
    "    create_comparison_grid,\n",
    "    create_segmentation_pipeline_viz\n",
    ")\n",
    "from src.pipe.processor import DiamondProcessor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths\n",
    "DATA_PATH = '../data/raw'\n",
    "OUTPUT_PATH = '../data/processed'\n",
    "VARIANT = 'Shape_1d_256i'\n",
    "\n",
    "# Initialize loader and mapper\n",
    "loader = DiamondDataLoader(DATA_PATH, VARIANT)\n",
    "mapper = DiamondShapeMapper()\n",
    "\n",
    "print(f\"Dataset: {VARIANT}\")\n",
    "print(f\"Output directory: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Single Image Segmentation Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample image\n",
    "SHAPE_ID = 1  # Asscher\n",
    "IMAGE_INDEX = 0\n",
    "\n",
    "shape_code = mapper.get_shape_code(SHAPE_ID)\n",
    "shape_name = mapper.get_shape_name(shape_code)\n",
    "\n",
    "# Load image\n",
    "images = loader.list_images(SHAPE_ID)\n",
    "image_path = loader.get_image_path(SHAPE_ID, images[IMAGE_INDEX])\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "print(f\"Processing: {shape_name} ({shape_code})\")\n",
    "print(f\"Image shape: {image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualize Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display original image\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'Original Image - {shape_name}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Preprocessing with CLAHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "original, enhanced = preprocess_for_segmentation(image)\n",
    "\n",
    "# Display comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(enhanced, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('CLAHE Enhanced')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Initialize GrabCut Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize mask\n",
    "h, w = image.shape[:2]\n",
    "mask = init_grabcut_mask(h, w)\n",
    "\n",
    "# Visualize mask\n",
    "mask_viz = visualize_mask(mask)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(mask_viz, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Initialized Mask')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Mask Legend:\")\n",
    "print(\"  Black: Definite Background\")\n",
    "print(\"  Dark Gray: Probable Background\")\n",
    "print(\"  Light Gray: Probable Foreground\")\n",
    "print(\"  White: Definite Foreground\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Apply GrabCut Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform segmentation\n",
    "segmented, binary_mask = remove_background(original, enhanced, iterations=5)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(binary_mask, cmap='gray')\n",
    "axes[1].set_title('Binary Mask')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(segmented, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Segmented Result')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Add Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add contours and bounding box\n",
    "annotated = annotate_segmentation(segmented, binary_mask)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(segmented, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Segmented')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('With Annotations')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Complete Pipeline Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show complete pipeline\n",
    "fig = create_segmentation_pipeline_viz(original, enhanced, binary_mask, segmented, figsize=(18, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Processing Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process multiple images from a shape category\n",
    "NUM_IMAGES = 10\n",
    "BATCH_SHAPE_ID = 2  # Brilliant\n",
    "\n",
    "shape_code = mapper.get_shape_code(BATCH_SHAPE_ID)\n",
    "shape_name = mapper.get_shape_name(shape_code)\n",
    "\n",
    "print(f\"Processing {NUM_IMAGES} images from {shape_name} ({shape_code})...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image list\n",
    "images = loader.list_images(BATCH_SHAPE_ID)\n",
    "sample_images = images[:NUM_IMAGES]\n",
    "\n",
    "# Process images\n",
    "results = []\n",
    "\n",
    "for img_name in tqdm(sample_images, desc=\"Processing\"):\n",
    "    img_path = loader.get_image_path(BATCH_SHAPE_ID, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    # Preprocess and segment\n",
    "    orig, enh = preprocess_for_segmentation(img)\n",
    "    seg, mask = remove_background(orig, enh, iterations=5)\n",
    "    \n",
    "    results.append((orig, seg, mask))\n",
    "\n",
    "print(f\"Processed {len(results)} images successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display grid of results\n",
    "fig, axes = plt.subplots(NUM_IMAGES, 2, figsize=(10, NUM_IMAGES * 2.5))\n",
    "fig.suptitle(f'Batch Processing Results - {shape_name}', fontsize=14, fontweight='bold')\n",
    "\n",
    "for idx, (orig, seg, mask) in enumerate(results):\n",
    "    axes[idx, 0].imshow(cv2.cvtColor(orig, cv2.COLOR_BGR2RGB))\n",
    "    axes[idx, 0].set_title(f'Original {idx+1}')\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    axes[idx, 1].imshow(cv2.cvtColor(seg, cv2.COLOR_BGR2RGB))\n",
    "    axes[idx, 1].set_title(f'Segmented {idx+1}')\n",
    "    axes[idx, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using DiamondProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor\n",
    "processor = DiamondProcessor(\n",
    "    data_loader=loader,\n",
    "    output_dir=OUTPUT_PATH,\n",
    "    iterations=5,\n",
    "    add_annotations=False\n",
    ")\n",
    "\n",
    "print(\"Processor initialized!\")\n",
    "print(f\"Output directory: {processor.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a single shape category (limited images for demo)\n",
    "DEMO_SHAPE_ID = 3  # Combination\n",
    "MAX_DEMO_IMAGES = 5\n",
    "\n",
    "results = processor.process_shape_category(\n",
    "    shape_id=DEMO_SHAPE_ID,\n",
    "    max_images=MAX_DEMO_IMAGES,\n",
    "    save_results=True\n",
    ")\n",
    "\n",
    "print(\"\\nProcessing complete!\")\n",
    "print(f\"Processed: {results['processed']}\")\n",
    "print(f\"Failed: {results['failed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison: Different Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results with different iteration counts\n",
    "test_image_path = loader.get_image_path(1, loader.list_images(1)[0])\n",
    "test_image = cv2.imread(test_image_path)\n",
    "orig, enh = preprocess_for_segmentation(test_image)\n",
    "\n",
    "iteration_counts = [1, 3, 5, 10]\n",
    "iteration_results = []\n",
    "\n",
    "for iters in iteration_counts:\n",
    "    seg, mask = remove_background(orig, enh, iterations=iters)\n",
    "    iteration_results.append(seg)\n",
    "\n",
    "# Display comparison\n",
    "fig, axes = plt.subplots(1, len(iteration_counts) + 1, figsize=(18, 4))\n",
    "fig.suptitle('Effect of GrabCut Iterations', fontsize=14, fontweight='bold')\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(orig, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "for idx, (iters, result) in enumerate(zip(iteration_counts, iteration_results), 1):\n",
    "    axes[idx].imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    axes[idx].set_title(f'{iters} iterations')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Measure processing time\n",
    "test_images = loader.list_images(1)[:10]\n",
    "processing_times = []\n",
    "\n",
    "for img_name in test_images:\n",
    "    img_path = loader.get_image_path(1, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    start = time.time()\n",
    "    orig, enh = preprocess_for_segmentation(img)\n",
    "    seg, mask = remove_background(orig, enh, iterations=5)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    processing_times.append(elapsed)\n",
    "\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"  Average time per image: {np.mean(processing_times):.3f} seconds\")\n",
    "print(f\"  Min time: {np.min(processing_times):.3f} seconds\")\n",
    "print(f\"  Max time: {np.max(processing_times):.3f} seconds\")\n",
    "print(f\"  Processing speed: {1/np.mean(processing_times):.2f} images/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Complete diamond segmentation pipeline\n",
    "2. CLAHE preprocessing for enhanced contrast\n",
    "3. GrabCut algorithm for background removal\n",
    "4. Contour detection and bounding box annotation\n",
    "5. Batch processing capabilities\n",
    "6. Performance analysis\n",
    "\n",
    "The pipeline successfully segments diamond images with high accuracy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}